{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting imaging and pathology reports for labelling\n",
    "\n",
    "\n",
    "Andres Tamm\n",
    "\n",
    "2022-08-31\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Prepare-reports-for-TNM-and-recurrence\" data-toc-modified-id=\"Prepare-reports-for-TNM-and-recurrence-1\">Prepare reports for TNM and recurrence</a></span></li><li><span><a href=\"#Select-reports-for-TNM-and-recurrence\" data-toc-modified-id=\"Select-reports-for-TNM-and-recurrence-2\">Select reports for TNM and recurrence</a></span><ul class=\"toc-item\"><li><span><a href=\"#Select-reports-for-TNM\" data-toc-modified-id=\"Select-reports-for-TNM-2.1\">Select reports for TNM</a></span></li><li><span><a href=\"#Recurrence\" data-toc-modified-id=\"Recurrence-2.2\">Recurrence</a></span></li></ul></li><li><span><a href=\"#Additional.-How-many-reports-to-select?\" data-toc-modified-id=\"Additional.-How-many-reports-to-select?-3\">Additional. How many reports to select?</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, truncnorm\n",
    "from itertools import product\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import textmining.utils as ut\n",
    "from textmining.recurrence import get_recurrence\n",
    "from textmining.reports import get_crc_reports\n",
    "from textmining.tnm.clean import add_tumour_tnm\n",
    "from textmining.tnm.tnm import get_tnm_phrase, get_tnm_values\n",
    "from textmining.crm_emvi import get_crm, get_emvi\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = Path(\"z:\\\\Andres\\\\project_textmining\\\\textmining\\\\\")\n",
    "code_path = root\n",
    "out_path  = root / 'labelled_data'\n",
    "data_path = root / 'data'\n",
    "\n",
    "print(out_path.exists())\n",
    "print(data_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare reports for TNM and recurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Gather reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get imaging types of interest\n",
    "img_path = code_path / \"textmining\" / \"vocab\" / \"NIHR-HIC_Colorectal-Cancer_imaging-types.xlsx\"\n",
    "img = pd.read_excel(img_path)\n",
    "img = img.loc[~img['needed for NIHR HIC CRC'].isin(['no', 'maybe'])]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500, 'display.min_rows', 10000, 'display.max_rows', 10000)\n",
    "display(img)\n",
    "\n",
    "codes = img.imaging_code.to_list()\n",
    "# Not including 'ZRMDT','ZRXTC','ZRXTFL','ZRXTI','ZRXTM','ZRXTN','ZRXTP','ZRXTUS','ZSECOP' - tend to be empty\n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get older OUH and RMH reports\n",
    "\n",
    "# Files\n",
    "files_img  = ['imaging_OUH_2022-08-17_144307.csv', 'imaging_RMH_2022-04-25_111348.csv']\n",
    "files_path = ['histopathology_OUH_2022-04-24_203630.csv', 'histopathology_RMH_2022-04-25_111342.csv']\n",
    "files_end = ['endoscopy_reports_OUH_2022-04-24_202454.csv']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Imaging reports\n",
    "for f in files_img:\n",
    "    print('\\n----Reading data from: {}'.format(f))\n",
    "    t = pd.read_csv(data_path / f)    \n",
    "    print('\\nColumns: {}'.format(t.columns.to_list()))\n",
    "    print('\\nShape of data: {}'.format(t.shape))\n",
    "    print('\\nImaging code is available for {}% of reports'.format((~t.imaging_code.isna()).mean()*100))\n",
    "    \n",
    "    # Imaging codes\n",
    "    c = t.imaging_code.value_counts()\n",
    "    print('\\nTop value counts of imaging codes: \\n{}'.format(c[0:10]))\n",
    "    mask = t.imaging_code.fillna('').str.lower().str.contains('|'.join(codes).lower(), regex=True)\n",
    "    t = t.loc[mask]\n",
    "    print('\\nShape of data after including relevant img reports: {}'.format(t.shape))  \n",
    "    \n",
    "    t = t[['brc', 'subject_id', 'imaging_date', 'imaging_report_date', 'imaging_code', 'report_text_anon']]\n",
    "    t = t.rename(columns={'imaging_report_date':'report_date'})\n",
    "    t['report_type'] = 'imaging'\n",
    "\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    t.report_date = pd.to_datetime(t.report_date)\n",
    "\n",
    "    df = pd.concat(objs=[df,t], axis=0)\n",
    "\n",
    "# Pathology reports\n",
    "for f in files_path:\n",
    "    print('\\n----Reading data from: {}'.format(f))\n",
    "    t = pd.read_csv(data_path / f)    \n",
    "    print('\\nColumns: {}'.format(t.columns.to_list()))\n",
    "    print('\\nShape of data: {}'.format(t.shape))\n",
    "\n",
    "    t = t[['brc', 'subject_id', 'authorised_date', 'report_text_anon']]\n",
    "    t = t.rename(columns={'authorised_date':'report_date'})\n",
    "    t['report_type'] = 'pathology'\n",
    "\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    t.report_date = pd.to_datetime(t.report_date)\n",
    "\n",
    "    df = pd.concat(objs=[df,t], axis=0)\n",
    "    \n",
    "# Endoscopy reports\n",
    "for f in files_end:\n",
    "    print('\\n----Reading data from: {}'.format(f))\n",
    "    t = pd.read_csv(data_path / f)    \n",
    "    print('\\nColumns: {}'.format(t.columns.to_list()))\n",
    "    print('\\nShape of data: {}'.format(t.shape))\n",
    "    \n",
    "    t = t[['brc', 'subject_id', 'exam_type', 'exam_date', 'report_text_anon']]\n",
    "    t = t.rename(columns={'exam_date':'report_date'})\n",
    "    t = t.loc[t.exam_type.str.lower().str.contains('colonos|sigmoidos')]\n",
    "    t['report_type'] = 'endoscopy'\n",
    "\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    t.report_date = pd.to_datetime(t.report_date)\n",
    "\n",
    "    df = pd.concat(objs=[df,t], axis=0)\n",
    "    \n",
    "# Some reports have duplicate texts - drop\n",
    "print('Shape before dropping duplicates: {}'.format(df.shape[0]))\n",
    "df = df.drop_duplicates(subset=['report_text_anon'])\n",
    "print('Shape after dropping duplicates: {}'.format(df.shape[0]))\n",
    "\n",
    "# Replace \\r and ” with \\n\\n, and \n",
    "#  Not having \\r simplifies reading csv from file (Pandas has issues otherwise)\n",
    "#  ” seems to mark sections in RMH reports and having \\n\\n simplifies viewing\n",
    "df.report_text_anon = df.report_text_anon.str.replace('\\r', '\\n\\n')\n",
    "df.report_text_anon = df.report_text_anon.str.replace('”', '\\n\\n')\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Summary\n",
    "print('\\n====SUMMARY====\\n\\n{}'.format(df.groupby(['brc', 'report_type']).size()))\n",
    "print('\\nTotal number of reports: {}'.format(df.shape[0]))\n",
    "print('\\nColumns: {}'.format(df.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check report date range --> potential to include future reports as test set\n",
    "df['report_date'] = pd.to_datetime(df['report_date'])\n",
    "s = df.groupby(['brc', 'report_type'])['report_date'].agg([np.min, np.max])\n",
    "print(s)\n",
    "\n",
    "#t = df.loc[df.brc=='OXFORD']\n",
    "#print(t.report_date.dt.year.value_counts().reset_index().sort_values(by='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Identify individuals with CRC in newer OUH data ----\n",
    "f0 = data_path / '20220526.vw_outpatient_attendances_diagnoses.csv'\n",
    "d0 = pd.read_csv(f0, usecols=['brc', 'subject', 'diagnosis_code_icd10', 'diagnosis_date'])\n",
    "d0['src'] = 'outpat'\n",
    "\n",
    "f1 = data_path / '20220526.vw_inpat_episodes_diagnoses.csv'\n",
    "d1 = pd.read_csv(f1, usecols=['brc', 'subject', 'diagnosis_code_icd10', 'diagnosis_date'])\n",
    "d1['src'] = 'inpat'\n",
    "\n",
    "d = pd.concat(objs=[d0, d1], axis=0)\n",
    "print(d.shape)\n",
    "\n",
    "print(d.diagnosis_date.iloc[0:5])\n",
    "d.diagnosis_date = pd.to_datetime(d.diagnosis_date)\n",
    "print(d.diagnosis_date.iloc[0:5])\n",
    "print(d.diagnosis_date.min(), d.diagnosis_date.max())\n",
    "print(d.diagnosis_date.sort_values().drop_duplicates())\n",
    "\n",
    "d = d.loc[d.diagnosis_code_icd10.fillna('').str.lower().str.contains('^c(?:18|19|20)', regex=True), :]\n",
    "print(d.diagnosis_code_icd10.unique())\n",
    "print(d.groupby('src')['subject'].nunique())\n",
    "\n",
    "crc = d.subject.unique()\n",
    "print(len(crc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Add newer OUH pathology reports for individuals with CRC ----\n",
    "f = data_path / '20220526.vw_pathology_reports.csv'\n",
    "#f = data_path / '20230329.vw_pathology_reports.csv'\n",
    "\n",
    "t = pd.read_csv(f)\n",
    "print(t.shape, t.columns)\n",
    "t = t.rename(columns={'patient_id': 'subject_id', 'date_received': 'report_date', 'safe_report': 'report_text_anon'})\n",
    "t = t.drop(labels=['calc_lab_no', 'date_authorised', 'snomed_t', 'snomed_m'], axis=1)\n",
    "print(t.shape, t.columns)\n",
    "\n",
    "print(t.report_date.iloc[0:5])\n",
    "t.report_date = pd.to_datetime(t.report_date, format='%d/%m/%Y %H:%M:%S')\n",
    "print(t.report_date.iloc[0:5])\n",
    "print(t.report_date.min(), t.report_date.max())\n",
    "\n",
    "t = t.loc[t.report_date >= '2021-01-01']\n",
    "#t = t.loc[t.report_date >= '2022-03-31']\n",
    "print(t.shape)\n",
    "\n",
    "t['brc'] = 'OXFORD'\n",
    "t['report_type'] = 'pathology_future'\n",
    "\n",
    "t = t.loc[t.subject_id.isin(crc)]\n",
    "print(t.shape)\n",
    "\n",
    "df = pd.concat(objs=[df, t], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tmp - compare old vs new path report data\n",
    "dfs = []\n",
    "\n",
    "for f in [data_path / '20220526.vw_pathology_reports.csv',\n",
    "          data_path / '20230329.vw_pathology_reports.csv']:\n",
    "\n",
    "    t = pd.read_csv(f)\n",
    "    print(t.shape, t.columns)\n",
    "    t = t.rename(columns={'patient_id': 'subject_id', 'date_received': 'report_date', 'safe_report': 'report_text_anon'})\n",
    "    t = t.drop(labels=['calc_lab_no', 'date_authorised', 'snomed_t', 'snomed_m'], axis=1)\n",
    "    print(t.shape, t.columns)\n",
    "\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    t.report_date = pd.to_datetime(t.report_date, format='%d/%m/%Y %H:%M:%S')\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    print(t.report_date.min(), t.report_date.max())\n",
    "\n",
    "    #t = t.loc[t.report_date >= '2021-01-01']\n",
    "    #t = t.loc[t.report_date >= '2022-03-31']\n",
    "    print(t.shape)\n",
    "\n",
    "    t['brc'] = 'OXFORD'\n",
    "    t['report_type'] = 'pathology_future'\n",
    "\n",
    "    dfs.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tmp - compare old vs new path report data\n",
    "# Seems there are very few new path reports ... maybe because most patients already had major operation?\n",
    "for t in dfs:\n",
    "    print('--')\n",
    "    print(t.shape)\n",
    "    print(t.report_date.min(), t.report_date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Add newer OUH imaging reports for individuals with CRC ----\n",
    "f = '20220526.vw_imaging.csv'\n",
    "#f = '20230329.vw_imaging.csv'\n",
    "print('\\n----Reading data from: {}'.format(f))\n",
    "t = pd.read_csv(data_path / f)    \n",
    "print('\\nColumns: {}'.format(t.columns.to_list()))\n",
    "print('\\nShape of data: {}'.format(t.shape))\n",
    "print('\\nImaging code is available for {}% of reports'.format((~t.imaging_code.isna()).mean()*100))\n",
    "\n",
    "# Imaging codes\n",
    "c = t.imaging_code.value_counts()\n",
    "print('\\nTop value counts of imaging codes: \\n{}'.format(c[0:10]))\n",
    "mask = t.imaging_code.fillna('').str.lower().str.contains('|'.join(codes).lower(), regex=True)\n",
    "t = t.loc[mask]\n",
    "print('\\nShape of data after including relevant img reports: {}'.format(t.shape))  \n",
    "\n",
    "# Reformat\n",
    "t = t[['brc', 'subject', 'imaging_date', 'imaging_report_date', 'imaging_code', 'anonymised_report']]\n",
    "t = t.rename(columns={'imaging_report_date':'report_date', 'subject': 'subject_id', \n",
    "                      'anonymised_report': 'report_text_anon'})\n",
    "t['report_type'] = 'imaging_future'\n",
    "\n",
    "# Date range\n",
    "print(t.report_date.iloc[0:5])\n",
    "t.report_date = pd.to_datetime(t.report_date, format='%d/%m/%Y %H:%M:%S')\n",
    "print(t.report_date.iloc[0:5])\n",
    "print(t.report_date.min(), t.report_date.max())\n",
    "t = t.loc[t.report_date >= '2021-01-01']\n",
    "#t = t.loc[t.report_date >= '2022-03-01']\n",
    "print(t.shape)\n",
    "\n",
    "# Retain CRC\n",
    "t = t.loc[t.subject_id.isin(crc)]\n",
    "print(t.shape)\n",
    "\n",
    "\n",
    "df = pd.concat(objs=[df, t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp - compare old vs new imaging reports\n",
    "dfs = []\n",
    "for f in ['20220526.vw_imaging.csv', '20230329.vw_imaging.csv']:\n",
    "    print('\\n----Reading data from: {}'.format(f))\n",
    "    t = pd.read_csv(data_path / f)    \n",
    "    print('\\nColumns: {}'.format(t.columns.to_list()))\n",
    "    print('\\nShape of data: {}'.format(t.shape))\n",
    "    print('\\nImaging code is available for {}% of reports'.format((~t.imaging_code.isna()).mean()*100))\n",
    "\n",
    "    # Imaging codes\n",
    "    c = t.imaging_code.value_counts()\n",
    "    print('\\nTop value counts of imaging codes: \\n{}'.format(c[0:10]))\n",
    "    mask = t.imaging_code.fillna('').str.lower().str.contains('|'.join(codes).lower(), regex=True)\n",
    "    t = t.loc[mask]\n",
    "    print('\\nShape of data after including relevant img reports: {}'.format(t.shape))  \n",
    "\n",
    "    # Reformat\n",
    "    t = t[['brc', 'subject', 'imaging_date', 'imaging_report_date', 'imaging_code', 'anonymised_report']]\n",
    "    t = t.rename(columns={'imaging_report_date':'report_date', 'subject': 'subject_id', \n",
    "                        'anonymised_report': 'report_text_anon'})\n",
    "    t['report_type'] = 'imaging_future'\n",
    "\n",
    "    # Date range\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    t.report_date = pd.to_datetime(t.report_date, format='%d/%m/%Y %H:%M:%S')\n",
    "    print(t.report_date.iloc[0:5])\n",
    "    print(t.report_date.min(), t.report_date.max())\n",
    "    #t = t.loc[t.report_date >= '2021-01-01']\n",
    "    #t = t.loc[t.report_date >= '2022-03-01']\n",
    "    print(t.shape)\n",
    "\n",
    "    dfs.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tmp - compare old vs new img report data\n",
    "# New imaging table has more reports but same max date \n",
    "# -- perhaps due to similar issue as with HIC data, where some img \n",
    "for t in dfs:\n",
    "    print('--')\n",
    "    print(t.shape)\n",
    "    print(t.report_date.min(), t.report_date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check count\n",
    "df.groupby(['brc', 'report_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop reports with duplicate text\n",
    "print(df.shape[0], df.report_text_anon.nunique(), df.drop_duplicates().shape[0])\n",
    "\n",
    "df = df.drop_duplicates(subset=['report_text_anon'])\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check count again\n",
    "df.groupby(['brc', 'report_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check date range again\n",
    "df['report_date'] = pd.to_datetime(df['report_date'])\n",
    "s = df.groupby(['brc', 'report_type'])['report_date'].agg([np.min, np.max])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reports with imaging codes starting with Z\n",
    "#tmp = df.loc[df.imaging_code.fillna('').str.contains('^Z')].report_text_anon.drop_duplicates()\n",
    "#tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For quick testing\n",
    "#df = df.sample(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "df.to_csv(out_path / 'all_reports.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reports \n",
    "df = pd.read_csv(out_path / 'all_reports.csv')\n",
    "print(df.shape[0], df.columns)\n",
    "\n",
    "# Date to datetime\n",
    "print(df.report_date.iloc[0:5])\n",
    "df.report_date = pd.to_datetime(df.report_date)\n",
    "\n",
    "# Use only small number of reports? For testing\n",
    "testmode = False\n",
    "if testmode:\n",
    "    df = df.sample(100, random_state=42)\n",
    "\n",
    "# Check count\n",
    "df.groupby(['brc', 'report_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find reports that describe current colorectal cancer, but do not remove non-crc reports (ran about 43 minutes for 74k reports)\n",
    "__, matches_crc = get_crc_reports(df, 'report_text_anon', add_subj_to_matches=True, subjcol='subject_id')\n",
    "\n",
    "df['row'] = np.arange(df.shape[0])\n",
    "df['crc_nlp'] = 0\n",
    "matches_incl = matches_crc.loc[matches_crc.exclusion_indicator==0]\n",
    "df.loc[df.row.isin(matches_incl.row), 'crc_nlp'] = 1\n",
    "print(df.groupby(['brc', 'report_type'])['crc_nlp'].sum())\n",
    "\n",
    "# Identify reports where all matches for CRC were marked as false \n",
    "# This helps check whether some cases of CRC may be completely missed when using the code\n",
    "# As otherwise, a report could be marked as describing CRC if it has at least one valid match\n",
    "df['row'] = np.arange(df.shape[0])\n",
    "df['false_crc_nlp'] = 0\n",
    "matches_excl = matches_crc.loc[matches_crc.exclusion_indicator==1]\n",
    "row_false = np.setdiff1d(matches_excl.row, matches_incl.row)\n",
    "df.loc[df.row.isin(row_false), 'false_crc_nlp'] = 1\n",
    "print(df.groupby(['brc', 'report_type'])['false_crc_nlp'].sum())\n",
    "\n",
    "# Save to disk\n",
    "os.chdir(out_path)\n",
    "#tstamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "\n",
    "fname = 'matches-crc.csv'\n",
    "print('\\nSaving matches to file {}...'.format(fname))\n",
    "matches_crc.to_csv(fname, index=False)\n",
    "\n",
    "fname = 'reports-all_crc-true_tnm-false_recur-false.csv'\n",
    "print('\\nSaving reports to file {}...'.format(fname))\n",
    "df.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read reports (with CRC status)\n",
    "read_from_disk=False\n",
    "if read_from_disk:\n",
    "    os.chdir(out_path)\n",
    "    files = os.listdir()\n",
    "    fname = [f for f in files if f.startswith('reports-all_crc-true_tnm-false_recur-false')][0]\n",
    "    print(fname)\n",
    "    df = pd.read_csv(fname)\n",
    "    print(df.crc_nlp.mean())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract TNM phrases (ran about 163 minutes for 74k reports)\n",
    "# TNM phrases marked as historical are not removed - could be removed later, and value extraction rerun\n",
    "matches_tnm, check_phrases_tnm, check_cleaning_tnm, check_rm_tnm = get_tnm_phrase(df=df, col='report_text_anon', \n",
    "                                                                                  remove_unusual=True, \n",
    "                                                                                  remove_historical=False, \n",
    "                                                                                  remove_falsepos=True)\n",
    "\n",
    "# Add nearby tumour keywords (can help decide which tumour the TNM phrase refers to, if needed)\n",
    "matches_tnm = add_tumour_tnm(df, matches_tnm, col_report='report_text_anon', targetcol='target_before_clean')\n",
    "\n",
    "# Get TNM values from phrases\n",
    "df, check_values_tnm = get_tnm_values(df, matches=matches_tnm, col='report_text_anon', pathology_prefix=False)\n",
    "\n",
    "# Mark all reports that have T, N or M values\n",
    "mask = ~(df['T'].isna() & df['N'].isna() & df['M'].isna())\n",
    "df['has_tnm'] = 0\n",
    "df.loc[mask, 'has_tnm'] = 1\n",
    "print('Number of reports with and without T, N or M value according to code:\\n\\n{}'.format(df.has_tnm.value_counts()))\n",
    "\n",
    "# Get excluded TNM matches & add indicator\n",
    "# This helps check reports that had some matches marked as invalid\n",
    "# Contrary to CRC detection, it is useful to check these, as the final result includes max and min of all matches marked as valid\n",
    "df['false_tnm'] = 0\n",
    "df['row'] = np.arange(df.shape[0])\n",
    "#row_false = np.setdiff1d(check_rm_tnm.row, matches_tnm.row)\n",
    "row_false = check_rm_tnm.row\n",
    "df.loc[df.row.isin(row_false), 'false_tnm'] = 1\n",
    "print(df.groupby(['brc', 'report_type'])['false_tnm'].mean())\n",
    "\n",
    "# Lil summary\n",
    "print('--------')\n",
    "cols = ['T', 'N', 'M']\n",
    "for c in cols:\n",
    "    print(c)\n",
    "    display(df[c].value_counts())\n",
    "    \n",
    "n = df.groupby(['brc', 'has_tnm']).size()\n",
    "ntot = df.groupby('brc').size()\n",
    "print(n)\n",
    "print(n/ntot)\n",
    "print('--------')\n",
    "\n",
    "# Save to disk for reference\n",
    "os.chdir(out_path)\n",
    "#tstamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "dfs   = [df, \n",
    "         matches_tnm, check_phrases_tnm, check_cleaning_tnm, check_rm_tnm]\n",
    "names = ['reports-all_crc-true_tnm-true_recur-false', \n",
    "         'tnm-matches', 'tnm-check-phrases', 'tnm-check-cleaning', 'tnm-check-rm']\n",
    "for n, d in zip(names,dfs):\n",
    "    fname = n + '.csv'\n",
    "    print('Saving to file {}...'.format(fname))\n",
    "    d.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reports (with CRC status and TNM staging)\n",
    "read_from_disk=True\n",
    "if read_from_disk:\n",
    "    os.chdir(out_path)\n",
    "    files = os.listdir()\n",
    "    fname = [f for f in files if f.startswith('reports-all_crc-true_tnm-true_recur-false')][0]\n",
    "    print(fname)\n",
    "    df = pd.read_csv(fname)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recurrence and metastasis (about 27 min per 74k reports)\n",
    "df, matches_rec = get_recurrence(df, 'report_text_anon', verbose=False)\n",
    "\n",
    "# Mark all reports that have recurrence or metastasis\n",
    "print(df.recurrence.unique(), df.metastasis.unique())\n",
    "df['has_recurrence'] = 0\n",
    "df.loc[~df['recurrence'].isna(), 'has_recurrence'] = 1\n",
    "df['has_metastasis'] = 0\n",
    "df.loc[~df['metastasis'].isna(), 'has_metastasis'] = 1\n",
    "print('Number of reports with recurrence:\\n\\n{}'.format(df.has_recurrence.value_counts()))\n",
    "print('Number of reports with metastasis:\\n\\n{}'.format(df.has_metastasis.value_counts()))\n",
    "\n",
    "# Add indicator for excluded matches\n",
    "ex_rec = matches_rec.loc[(matches_rec.exclusion_indicator==1) & (matches_rec.concept=='recurrence')]\n",
    "print(ex_rec.shape[0])\n",
    "df['false_recur'] = 0\n",
    "df['row'] = np.arange(df.shape[0])\n",
    "df.loc[df.row.isin(ex_rec.row), 'false_recur'] = 1\n",
    "print(df.groupby(['brc', 'report_type'])['false_recur'].mean())\n",
    "\n",
    "ex_met = matches_rec.loc[(matches_rec.exclusion_indicator==1) & (matches_rec.concept=='metastasis')]\n",
    "print(ex_met.shape[0])\n",
    "df['false_met'] = 0\n",
    "df['row'] = np.arange(df.shape[0])\n",
    "df.loc[df.row.isin(ex_met.row), 'false_met'] = 1\n",
    "print(df.groupby(['brc', 'report_type'])['false_met'].mean())\n",
    "\n",
    "# Save to disk for reference\n",
    "os.chdir(out_path)\n",
    "#tstamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "dfs   = [df, matches_rec]\n",
    "names = ['reports-all_crc-true_tnm-true_recur-true', 'recur-matches']\n",
    "for n, d in zip(names,dfs):\n",
    "    fname = n + '.csv'\n",
    "    print('Saving to file {}...'.format(fname))\n",
    "    d.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reports (with CRC status and TNM staging and recurrence)\n",
    "read_from_disk=False\n",
    "if read_from_disk:\n",
    "    os.chdir(out_path)\n",
    "    files = os.listdir()\n",
    "    fname = [f for f in files if f.startswith('reports-all_crc-true_tnm-true_recur-true')][0]\n",
    "    print(fname)\n",
    "    df = pd.read_csv(fname)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get crm\n",
    "df, matches_crm, nonmatches_crm = get_crm(df, 'report_text_anon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get emvi\n",
    "df, matches_emvi, nonmatches_emvi = get_emvi(df, 'report_text_anon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk for reference\n",
    "os.chdir(out_path)\n",
    "#tstamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "dfs   = [df, matches_crm, nonmatches_crm, matches_emvi, nonmatches_emvi]\n",
    "names = ['reports-all_crc-true_tnm-true_recur-true_crmemvi-true', 'crm-matches', 'crm-nonmatches', 'emvi-matches', 'emvi-nonmatches']\n",
    "for n, d in zip(names,dfs):\n",
    "    fname = n + '.csv'\n",
    "    print('Saving to file {}...'.format(fname))\n",
    "    d.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 1.3. Double check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(out_path)\n",
    "[f for f in files if f.startswith('reports-all_crc-true_tnm-true_recur-true_crmemvi-true')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read reports\n",
    "#  NB -- need to have lineterminator='\\n' (works with c engine), as otherwise '\\r' interpreted as lineterminator too\n",
    "#usecols = ['brc', 'subject_id', 'row', 'imaging_date', 'report_date', 'imaging_code',\n",
    "#           'report_text_anon', 'report_type', 'crc_nlp', 'has_tnm', 'has_recurrence', 'has_metastasis',\n",
    "#           'false_tnm', 'false_recur', 'T', 'T_sub', 'T_min', 'T_sub_min', 'N', 'N_sub']\n",
    "os.chdir(out_path)\n",
    "files = os.listdir()\n",
    "#fname = [f for f in files if f.startswith('reports-all_crc-true_tnm-true_recur-true')][0]\n",
    "fname = 'reports-all_crc-true_tnm-true_recur-true_crmemvi-true.csv'\n",
    "print('Reading from file {}'.format(fname))\n",
    "#df = pd.read_csv(fname, usecols=None, engine='c', sep=',', lineterminator='\\n')\n",
    "df = pd.read_csv(fname)\n",
    "\n",
    "print('\\nColumns: {}'.format(df.columns))\n",
    "print('Shape: {}'.format(df.shape))\n",
    "print('Proportion of reports with crc ({:.2f}), recurrence ({:.2f}), tnm ({:.2f}), metastasis ({:.2f})'.format(\\\n",
    "       df.crc_nlp.mean(), df.has_recurrence.mean(), df.has_tnm.mean(), df.has_metastasis.mean()))\n",
    "print('Unique values for BRC (dummy checking read csv):{}'.format(df.brc.unique()))\n",
    "#display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts\n",
    "def count(df, vcol, gcols=['report_type']):\n",
    "    st = df.groupby(gcols)[vcol].size().rename('n')\n",
    "    s0 = df.groupby(gcols)[vcol].sum().rename('count')\n",
    "    s1 = df.groupby(gcols)[vcol].mean().round(3).rename('percent')\n",
    "    s1 *= 100\n",
    "    s = pd.concat(objs=[st, s0, s1], axis=1)\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['crc_nlp', 'false_crc_nlp']\n",
    "for vcol in cols:\n",
    "    print('\\n---{}'.format(vcol))\n",
    "    print(count(df, vcol, ['report_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['has_tnm', 'false_tnm']\n",
    "for vcol in cols:\n",
    "    print('\\n---{}'.format(vcol))\n",
    "    print(count(df, vcol, ['report_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['has_recurrence', 'false_recur']\n",
    "for vcol in cols:\n",
    "    print('\\n---{}'.format(vcol))\n",
    "    print(count(df, vcol, ['report_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['has_metastasis', 'false_met']\n",
    "for vcol in cols:\n",
    "    print('\\n---{}'.format(vcol))\n",
    "    print(count(df, vcol, ['report_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check matches for pathology future - why does it seem to have more false tnm?\n",
    "# Seems that certain reporting format is used more\n",
    "fname = 'tnm-check-rm.csv'\n",
    "print('Reading from file {}'.format(fname))\n",
    "#df = pd.read_csv(fname, usecols=None, engine='c', sep=',', lineterminator='\\n')\n",
    "matches = pd.read_csv(fname)\n",
    "print(matches.shape, matches.columns)\n",
    "print(df.shape[0])\n",
    "\n",
    "df['row'] = np.arange(df.shape[0])\n",
    "\n",
    "mask = (df.report_type == 'pathology_future') & (df.false_tnm == 1)\n",
    "rows = df.loc[mask, 'row']\n",
    "m = matches.loc[matches.row.isin(rows)]\n",
    "print(m.shape, m.row.nunique())\n",
    "m[['left', 'target', 'right', 'exclusion_reason']].drop_duplicates(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check matches for imaging - why does it seem to have so many false crc?\n",
    "# Seems that certain reporting format is used more\n",
    "fname = 'matches-crc.csv'\n",
    "print('Reading from file {}'.format(fname))\n",
    "#df = pd.read_csv(fname, usecols=None, engine='c', sep=',', lineterminator='\\n')\n",
    "matches = pd.read_csv(fname)\n",
    "print(matches.shape, matches.columns)\n",
    "print(df.shape[0])\n",
    "\n",
    "mask = (df.report_type == 'imaging') & (df.false_crc_nlp == 1)\n",
    "rows = df.loc[mask, 'row']\n",
    "m = matches.loc[matches.row.isin(rows)]\n",
    "print(m.shape, m.row.nunique())\n",
    "m[['left', 'target', 'right', 'exclusion_reason']].drop_duplicates(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Mark reports that were previously labelled and used multiple times in code development - excluding these just in case\n",
    "os.chdir(data_path)\n",
    "files = os.listdir()\n",
    "files = [f for f in files if f.startswith('reports-labelled')]\n",
    "print(files)\n",
    "\n",
    "ex = pd.DataFrame()\n",
    "for f in files:\n",
    "    e = pd.read_csv(f, engine='c', sep=',', lineterminator='\\n')\n",
    "    if 'date' in e.columns:\n",
    "        e = e.rename(columns={'date':'report_date'})\n",
    "    e = e.rename(columns={'subject':'subject_id', 'safe_report':'report_text_anon'})\n",
    "    e = e[['subject_id', 'report_text_anon', 'report_date', 'report_type']]\n",
    "    print(e.shape, e.columns)\n",
    "    ex = pd.concat(objs=[ex, e], axis=0)\n",
    "ex = ex.drop_duplicates(subset=['report_text_anon'])\n",
    "print(ex.shape)\n",
    "\n",
    "# For consistency\n",
    "ex.report_text_anon = ex.report_text_anon.str.replace('\\r', '\\n\\n')\n",
    "ex.report_text_anon = ex.report_text_anon.str.replace('”', '\\n\\n')\n",
    "\n",
    "# Dbl check - unmatched reports mostly endoscopy, though 12 img reports - not sure why\n",
    "mask = ex.report_text_anon.isin(df.report_text_anon)\n",
    "test = ex.loc[~mask]\n",
    "print(test.report_type.value_counts())\n",
    "test = test.loc[test.report_type=='imaging_relevant']\n",
    "test = test.merge(df.rename(columns={'report_text_anon': 'r'})[['subject_id', 'report_date', 'r']], how='left')\n",
    "print(test.shape)\n",
    "\n",
    "# Remove\n",
    "print('---')\n",
    "\n",
    "mask = df.report_text_anon.isin(ex.report_text_anon)\n",
    "print(mask.sum())\n",
    "print(df.shape)\n",
    "df = df.loc[~mask]\n",
    "print(df.shape)\n",
    "print(df.crc_nlp.mean(), df.has_recurrence.mean(), df.has_tnm.mean(), df.has_metastasis.mean())\n",
    "print(df.crc_nlp.sum(), df.has_recurrence.sum(), df.has_tnm.sum(), df.has_metastasis.sum())\n",
    "print('-----')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = pd.read_csv(os.path.join(out_path, 'recur-matches.csv'))\n",
    "\n",
    "# Dbl check the large proportion of false recur matches in imaging reports \n",
    "# Seems that many are negated, but many also historic\n",
    "# Currently, matches preceded by 'clinical information' are classified historic\n",
    "t = ex.loc[ex.row.isin(df.loc[(df.report_type=='imaging')&(df.brc=='RMH')].row)]\n",
    "print(t.shape)\n",
    "print(t.exclusion_reason.value_counts())\n",
    "tsub = t.sample(100, random_state=42)[['row','left', 'target', 'right', 'exclusion_reason']]\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500, 'display.min_rows', 20, 'display.max_rows', 20)\n",
    "display(tsub)\n",
    "\n",
    "display(tsub.loc[tsub.exclusion_reason.fillna('').str.contains('historic')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many reports have both CRC, TNM and recurrence \n",
    "#  Doesn't seem there's large overlap + recur needs to be extracted from reports that are not directly CRC reports\n",
    "df[['crc_nlp', 'has_tnm', 'has_recurrence']].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many reports have CRC and TNM\n",
    "df[['crc_nlp', 'has_tnm']].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check report counts \n",
    "s = df[['brc', 'report_type', 'crc_nlp', 'has_tnm']].value_counts().rename('n').reset_index()\n",
    "s = s.sort_values(['brc', 'report_type', 'crc_nlp', 'has_tnm'])\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500, 'display.min_rows', 50, 'display.max_rows', 50)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dbl check report counts \n",
    "s = df[['brc', 'report_type', 'crc_nlp', 'has_tnm', 'false_tnm']].value_counts().rename('n').reset_index()\n",
    "s = s.sort_values(['brc', 'report_type', 'crc_nlp', 'has_tnm', 'false_tnm'])\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500, 'display.min_rows', 50, 'display.max_rows', 50)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check reports where min and max T-stage differ\n",
    "\"\"\"\n",
    "cols = ['T_pre_indecision', 'T_indecision',\n",
    "       'T_sub_indecision', 'N_indecision', 'N_sub_indecision', 'M_indecision',\n",
    "       'M_sub_indecision']\n",
    "df[cols].mean(axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('\\n====')\n",
    "    row = dfsub.iloc[i]\n",
    "    print(row['T'], row['T_min'])\n",
    "    print(row.report_text_anon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check report counts \n",
    "s = df[['brc', 'report_type', 'has_recurrence', 'has_metastasis']].value_counts().rename('n').reset_index()\n",
    "s = s.sort_values(['brc', 'report_type'])\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500, 'display.min_rows', 50, 'display.max_rows', 50)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Select reports for TNM and CRC (2023-05-14)\n",
    "\n",
    "---- Newer report selection strategy ----\n",
    "\n",
    "Set 1\n",
    "* TNM : [OXFORD] x [img, path] x [has_tnm, ~has_tnm] -> 4 categories -> 400 reports\n",
    "* CRC : [OXFORD] x [img, path] x [has_crc, ~has_crc] -> 4 categories -> 400 reports\n",
    "\n",
    "Set 2\n",
    "* TNM : [OXFORD_FUTURE] x [img, path] x [has_tnm, ~has_tnm] -> 4 categories -> 400 reports\n",
    "* CRC : [OXFORD_FUTURE] x [img, path] x [has_crc, ~has_crc] -> 4 categories -> 400 reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reports\n",
    "#  NB -- in previous version, needed to have lineterminator='\\n' (works with c engine), as otherwise '\\r' interpreted as lineterminator too\n",
    "#usecols = ['brc', 'subject_id', 'row', 'imaging_date', 'report_date', 'imaging_code',\n",
    "#           'report_text_anon', 'report_type', 'crc_nlp', 'has_tnm', 'has_recurrence', 'has_metastasis',\n",
    "#           'false_tnm', 'false_recur', 'T', 'T_sub', 'T_min', 'T_sub_min', 'N', 'N_sub']\n",
    "os.chdir(out_path)\n",
    "files = os.listdir()\n",
    "#fname = [f for f in files if f.startswith('reports-all_crc-true_tnm-true_recur-true')][0]\n",
    "fname = 'reports-all_crc-true_tnm-true_recur-true_crmemvi-true.csv'\n",
    "print('Reading from file {}'.format(fname))\n",
    "#df = pd.read_csv(fname, usecols=None, engine='c', sep=',', lineterminator='\\n')\n",
    "df = pd.read_csv(fname)\n",
    "\n",
    "print('\\nColumns: {}'.format(df.columns))\n",
    "print('Shape: {}'.format(df.shape))\n",
    "print('Proportion of reports with crc ({:.2f}), recurrence ({:.2f}), tnm ({:.2f}), metastasis ({:.2f})'.format(\\\n",
    "       df.crc_nlp.mean(), df.has_recurrence.mean(), df.has_tnm.mean(), df.has_metastasis.mean()))\n",
    "print('Unique values for BRC (dummy checking read csv):{}'.format(df.brc.unique()))\n",
    "#display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if min-max values are the same, retain max only\n",
    "cols = ['T_pre', 'T', 'N', 'M', 'V', 'R', 'L', 'Pn', 'SM', 'H', 'G', 'CRM', 'EMVI']\n",
    "cols_min = [c + '_min' for c in cols]\n",
    "for c, cmin in zip(cols, cols_min):\n",
    "    print('--')\n",
    "    print(c, cmin)\n",
    "\n",
    "    mask = df[c] == df[cmin]\n",
    "    print(mask.sum())\n",
    "    #print(df.loc[mask, [c, cmin]])\n",
    "    df.loc[mask, cmin] = np.nan\n",
    "    #print(df.loc[mask, [c, cmin]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(dfsub, n_select, rng):\n",
    "\n",
    "    # Randomly sample indices\n",
    "    n = dfsub.shape[0]\n",
    "    #n_select = np.floor(p_select*n).astype(int)\n",
    "    c = n_select/n*100\n",
    "    if n < n_select:\n",
    "        i = np.arange(n)\n",
    "    else:\n",
    "        i = rng.choice(n, n_select, replace=False)\n",
    "    \n",
    "    # Retain sampled indices\n",
    "    return dfsub.iloc[i,:], c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['brc', 'report_type']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "n_select = 100\n",
    "#p_select  = 0.05\n",
    "dfa = pd.DataFrame()\n",
    "dfb = pd.DataFrame()\n",
    "#dfc = pd.DataFrame()\n",
    "suma  = pd.DataFrame()\n",
    "sumb  = pd.DataFrame()\n",
    "\n",
    "# ---- REPORTS WITH AND WITHOUT TNM ----\n",
    "\n",
    "# Oxford reports\n",
    "for has_tnm in [0, 1]:\n",
    "    for report_type in ['pathology', 'imaging']:\n",
    "        for brc in ['OXFORD']:\n",
    "\n",
    "            # Subset the data\n",
    "            mask = (df.has_tnm == has_tnm) & (df.report_type == report_type) & (df.brc == brc)\n",
    "            dfsub = df.loc[mask].copy()\n",
    "            n = dfsub.shape[0]\n",
    "            print(n, n_select)\n",
    "            dfsub, c = select(dfsub, n_select, rng)\n",
    "            dfa = pd.concat(objs=[dfa, dfsub], axis=0)\n",
    "\n",
    "            # Summarise\n",
    "            s = pd.DataFrame([[brc, dfsub.has_tnm.mean(), report_type, dfsub.crc_nlp.mean(), dfsub.false_tnm.mean(), n, n_select, seed, c]])\n",
    "            s.columns = ['brc', 'has_tnm', 'report_type', 'crc_nlp', 'false_tnm', 'n', 'n_select', 'seed', 'coverage (%)']\n",
    "            suma = pd.concat(objs=[suma, s], axis=0)\n",
    "\n",
    "\n",
    "# ---- REPORTS WITH AND WITHOUT CRC ----\n",
    "\n",
    "# Oxford reports\n",
    "for crc_nlp in [0, 1]:\n",
    "    for report_type in ['pathology', 'imaging']:\n",
    "        for brc in ['OXFORD']:\n",
    "\n",
    "            # Subset the data\n",
    "            mask = (df.crc_nlp == crc_nlp) & (df.report_type == report_type) & (df.brc == brc)\n",
    "            dfsub = df.loc[mask].copy()\n",
    "            n = dfsub.shape[0]\n",
    "            print(n, n_select)\n",
    "            dfsub, c = select(dfsub, n_select, rng)\n",
    "            dfb = pd.concat(objs=[dfb, dfsub], axis=0)\n",
    "\n",
    "            # Summarise\n",
    "            s = pd.DataFrame([[brc, dfsub.has_tnm.mean(), report_type, dfsub.crc_nlp.mean(), dfsub.false_tnm.mean(), n, n_select, seed, c]])\n",
    "            s.columns = ['brc', 'has_tnm', 'report_type', 'crc_nlp', 'false_tnm', 'n', 'n_select', 'seed', 'coverage (%)']\n",
    "            sumb = pd.concat(objs=[sumb, s], axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.crc_nlp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dbl check logic of selecting OUH reports\n",
    "dfox = df.loc[(df.brc == 'OXFORD') & (df.report_type.isin(['imaging', 'pathology']))]\n",
    "print(dfox.report_type.unique(), dfox.brc.unique())\n",
    "\n",
    "# 16% have TNM predicted by alg, makes sense to stratify by TNM\n",
    "print(dfox.has_tnm.mean())\n",
    "\n",
    "# 29% have CRC according to algorithm, makes sense to stratify\n",
    "print(dfox.crc_nlp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dbl check logic of selecting OUH reports: 16% have TNM predicted by alg, makes sense to stratify by TNM\n",
    "s = dfox.groupby('has_tnm')['crc_nlp'].value_counts(normalize=True, sort=False)\n",
    "print(s)\n",
    "\n",
    "s = dfox.groupby('crc_nlp')['has_tnm'].value_counts(normalize=True, sort=False)\n",
    "print(s)\n",
    "\n",
    "s = dfox.groupby('has_tnm')['crc_nlp'].value_counts(normalize=False, sort=False)\n",
    "print(s)\n",
    "\n",
    "s = dfox.groupby('crc_nlp')['has_tnm'].value_counts(normalize=False, sort=False)\n",
    "print(s)\n",
    "\n",
    "\"\"\"Note\n",
    "\n",
    "When selecting randomly from has_tnm subgroups,\n",
    "about 17 of 100 reports will have no TNM but CRC\n",
    "\n",
    "When selecting randomly from crc_nlp subgroups,\n",
    "about 52 of 100 will have no TNM but CRC\n",
    "\n",
    "Estimate of PPV skewed? [AT comment 2025-07-21: estimate of PPV could be skewed \n",
    "if evaluating the TNM and CRC algorithms on the same set of reports, not separately as done in this notebook.]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.report_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub = df.loc[(df.crc_nlp == 1) & (df.has_tnm == 0)]\n",
    "\n",
    "dfsub.report_text_anon.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check\n",
    "s = dfa.groupby(['brc', 'has_tnm', 'report_type', 'crc_nlp']).size().rename('n_select').reset_index()\n",
    "s = s.sort_values(['brc', 'crc_nlp', 'has_tnm'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check\n",
    "s = dfb.groupby(['brc', 'has_tnm', 'report_type', 'crc_nlp']).size().rename('n_select').reset_index()\n",
    "s = s.sort_values(['brc', 'report_type', 'crc_nlp', 'has_tnm'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check false_tnm proportion\n",
    "dfa.groupby(['brc', 'report_type', 'crc_nlp', 'has_tnm'])['false_tnm'].value_counts().rename('n').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dbl check there are no duplicates\n",
    "print(dfa.shape)\n",
    "print(dfa.drop_duplicates(subset=['report_text_anon']).shape)\n",
    "\n",
    "print(dfb.shape)\n",
    "print(dfb.drop_duplicates(subset=['report_text_anon']).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort reports randomly\n",
    "dfa_sort = dfa.sample(n=dfa.shape[0], random_state=42, replace=False)\n",
    "print(dfa_sort.drop_duplicates().shape[0] == dfa_sort.shape[0])\n",
    "\n",
    "dfb_sort = dfb.sample(n=dfb.shape[0], random_state=42, replace=False)\n",
    "print(dfb_sort.drop_duplicates().shape[0] == dfb_sort.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save (duplicates - orig file, and file to be modified by checking labels)\n",
    "#tstamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "fnames = ['set1_tnm.csv', 'set1_tnm_labelled.csv']\n",
    "for fname in fnames:\n",
    "    print('Saving to {}'.format(fname))\n",
    "    dfa_sort.to_csv(out_path / fname, index=False)\n",
    "\n",
    "    # Dbl check that file can be read \n",
    "    test = pd.read_csv(out_path / fname) #, engine='c', lineterminator='\\n')\n",
    "    print(test.brc.unique())\n",
    "\n",
    "\n",
    "# Save\n",
    "#tstamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "fnames = ['set1_crc.csv', 'set1_crc_labelled.csv']\n",
    "for fname in fnames:\n",
    "    print('Saving to {}'.format(fname))\n",
    "    dfb_sort.to_csv(out_path / fname, index=False)\n",
    "\n",
    "    # Dbl check that file can be read \n",
    "    test = pd.read_csv(out_path / fname) #, engine='c', lineterminator='\\n')\n",
    "    print(test.brc.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dbl check T, N, M proportion separately in set1\n",
    "df = pd.read_csv(out_path / 'set1_tnm.csv')\n",
    "print(df.shape)\n",
    "\n",
    "cols = ['T', 'N', 'M']\n",
    "for c in cols:\n",
    "    test = (~df[c].isna()).sum()\n",
    "    print('{}: {}, unique: {}'.format(c, test, df[c].unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dbl check T, N, M proportion separately in set2\n",
    "df = pd.read_csv(out_path / 'set2_tnm.csv')\n",
    "print(df.shape)\n",
    "\n",
    "cols = ['T', 'N', 'M']\n",
    "for c in cols:\n",
    "    test = (~df[c].isna()).sum()\n",
    "    print('{}: {}, unique: {}'.format(c, test, df[c].unique().tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional. How many reports to select?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the probability that p_hat differs from p by more than e, given sample size n?\n",
    "n = 100\n",
    "e = 0.05\n",
    "\n",
    "# Assume that asymptotic distribution of p_hat-p=delta ~ N(0, p(1-p)/n)\n",
    "\n",
    "#----\n",
    "# Method 1 \n",
    "#----\n",
    "\n",
    "## Assume fixed population proportion p\n",
    "## 1-cdf - probability that delta greater than e\n",
    "## *2, as can also be smaller than e\n",
    "p    = 0.9\n",
    "se   = np.sqrt(p*(1-p)/n)\n",
    "prob = (1 - norm.cdf(x=e, loc=0, scale=se))*2\n",
    "print('\\nFor n={}, probability that p_hat differs from p by more than {}: {}'.format(n, e, prob))\n",
    "\n",
    "## ppf - inverse of cdf\n",
    "alpha=0.05\n",
    "q = norm.ppf((1-alpha/2), loc=0, scale=1)\n",
    "print(q)\n",
    "ci = [p-q*se, p+q*se]\n",
    "print('{}% ci: {}'.format((1-alpha)*100, ci))\n",
    "#print('\\nn={} helps ensure that probability that p_hat differs from p by more than {} is {}'.format(n, e, prob_desired))\n",
    "\n",
    "#----\n",
    "# Method 2 \n",
    "#----\n",
    "\n",
    "## Assume population proportion p is drawn from truncated normal \n",
    "## with mu=p, std=0.05, and bounded in [0,1]\n",
    "myclip_a = 0\n",
    "myclip_b = 1\n",
    "my_mean  = p\n",
    "my_std   = 0.05\n",
    "a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = truncnorm.pdf(x, a=a, b=b, loc=my_mean, scale=my_std)\n",
    "plt.plot(x, y)\n",
    "print('\\nPrior')\n",
    "plt.show()\n",
    "\n",
    "## Simulate p from truncated normal\n",
    "## For each value of p, simulate delta from N(0, se_hat)\n",
    "nsim  = 100000  # Number of simulations\n",
    "psim  = truncnorm.rvs(a=a, b=b, loc=my_mean, scale=my_std, size=nsim) # Simulate p from prior\n",
    "se    = np.sqrt(psim*(1-psim)/n) # Derive se\n",
    "delta = norm.rvs(loc=0, scale=se, size=nsim) # Simulate delta\n",
    "\n",
    "mask = np.abs(delta) > e\n",
    "prob = mask.sum()/len(mask)  # Estimate probability\n",
    "print('\\nFor n={}, Bayesian probability that p_hat differs from p by more than {}: {}'.format(n, e, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CIs for population proportion\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "n = 100\n",
    "successes = int(0.9*n)\n",
    "ci = proportion_confint(count=successes, nobs=n, alpha=0.05, method='normal')\n",
    "print(ci)\n",
    "ci = proportion_confint(count=successes, nobs=n, alpha=0.05, method='wilson')\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that entered data corresponds to labeller.R display\n",
    "\"\"\"\n",
    "os.chdir(out_path)\n",
    "f = 'reports-labelled-tnm_20210803_1710.csv'\n",
    "df = pd.read_csv(f)\n",
    "\n",
    "for i in range(30):\n",
    "    print('---{}---'.format(i+1))\n",
    "    print(df.iloc[i])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('textmining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8a4a67cba11f68f6de4afefdc465f9586aab4899f26c72b0fdd85b5665768f50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
